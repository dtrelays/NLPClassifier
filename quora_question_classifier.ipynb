{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import tqdm\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Concatenate, Dense, Input,Dropout\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, RobertaTokenizer, RobertaForSequenceClassification, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder path where your CSV files are located\n",
    "folder_path = \"/Users/kianathakkar/Documents/dataset/quora-question-pairs/train.csv\"\n",
    "\n",
    "df_train = pd.read_csv(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder path where your CSV files are located\n",
    "folder_path_test = \"/Users/kianathakkar/Documents/dataset/quora-question-pairs/test.csv\"\n",
    "\n",
    "df_test = pd.read_csv(folder_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/kianathakkar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Tokenization and Lemmatization\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and Cleaning Text Data\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    # Check if the input is a non-empty string\n",
    "    if isinstance(text, str) and text.strip():  # Check if it's a non-empty string\n",
    "        # Lowercase the text\n",
    "        text = text.lower()\n",
    "\n",
    "        # Replace certain special characters with their string equivalents\n",
    "        text = text.replace('%', ' percent')\n",
    "        text = text.replace('$', ' dollar ')\n",
    "        text = text.replace('₹', ' rupee ')\n",
    "        text = text.replace('€', ' euro ')\n",
    "        text = text.replace('@', ' at ')\n",
    "        \n",
    "        # The pattern '[math]' appears around 900 times in the whole dataset.\n",
    "        text = text.replace('[math]', '')       \n",
    "\n",
    "        # Remove special characters and numbers\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "         \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary of common English contractions and their expanded forms\n",
    "contractions_dict = {\n",
    "    \"ain't\": \"is not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"I'd\": \"I would\",\n",
    "    \"I'll\": \"I will\",\n",
    "    \"I'm\": \"I am\",\n",
    "    \"I've\": \"I have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "# Function to expand contractions\n",
    "def expand_contractions(text, contractions_dict):\n",
    "    \n",
    "    if isinstance(text, str):\n",
    "        words = text.split()\n",
    "        expanded_words = [contractions_dict.get(word, word) for word in words]\n",
    "        expanded_text = \" \".join(expanded_words)\n",
    "        return expanded_text\n",
    "    else:\n",
    "        return text \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and Lemmatization\n",
    "def tokenize_and_lemmatize(text):\n",
    "    if isinstance(text, str):\n",
    "        words = text.split()\n",
    "        words = [lemmatizer.lemmatize(word) for word in words]\n",
    "        return ' '.join(words)\n",
    "    else:\n",
    "        return text  # Return the input as is if it's not a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List of column names to clean\n",
    "columns_to_clean = ['question1','question2']\n",
    "\n",
    "# Apply the functions to each column in the DataFrame\n",
    "for column in columns_to_clean:\n",
    "    # Apply the special character removal function\n",
    "    df_train[column] = df_train[column].apply(preprocess_text)\n",
    "    df_test[column] = df_test[column].apply(preprocess_text)\n",
    "\n",
    "    # Apply the contraction expansion function\n",
    "    df_train[column] = df_train[column].apply(expand_contractions, args=(contractions_dict,))\n",
    "    df_test[column] = df_test[column].apply(expand_contractions, args=(contractions_dict,))   \n",
    "     \n",
    "    # Apply the stop word removal function\n",
    "    df_train[column] = df_train[column].apply(tokenize_and_lemmatize)\n",
    "    df_test[column] = df_test[column].apply(tokenize_and_lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['question1'] = df_train['question1'].astype(str)\n",
    "df_train['question2'] = df_train['question2'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have preprocessed text in 'question1' and 'question2' columns\n",
    "question1_texts = df_train['question1'].apply(lambda x: str(x))\n",
    "question2_texts = df_train['question2'].apply(lambda x: str(x))\n",
    "\n",
    "# Tokenize the text in both columns\n",
    "question1_tokens = [word_tokenize(text) for text in question1_texts]\n",
    "question2_tokens = [word_tokenize(text) for text in question2_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a list to store the lengths of the internal lists\n",
    "lengths = [len(internal_list) for internal_list in question1_tokens]\n",
    "\n",
    "# Create a histogram\n",
    "plt.hist(lengths, bins=20)  # Adjust the number of bins as needed\n",
    "plt.xlabel('Length of Question')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Question Lengths')\n",
    "\n",
    "# Show the histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and sequence padding\n",
    "max_seq_length = 40  # Define your maximum sequence length\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(question1_tokens + question2_tokens)\n",
    "\n",
    "question1_sequences = tokenizer.texts_to_sequences(question1_tokens)\n",
    "question2_sequences = tokenizer.texts_to_sequences(question2_tokens)\n",
    "question1_sequences = pad_sequences(question1_sequences, maxlen=max_seq_length)\n",
    "question2_sequences = pad_sequences(question2_sequences, maxlen=max_seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X = np.column_stack((question1_sequences, question2_sequences))\n",
    "y = df_train['is_duplicate'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-06 16:59:37.320553: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-06 16:59:37.321000: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-06 16:59:37.321561: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-06 16:59:37.390617: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-06 16:59:37.391068: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-06 16:59:37.391489: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "# Build the LSTM model\n",
    "embedding_dim = 100  \n",
    "lstm_units = 64\n",
    "\n",
    "input1 = Input(shape=(max_seq_length,))\n",
    "input2 = Input(shape=(max_seq_length,))\n",
    "\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=embedding_dim)\n",
    "lstm_layer = LSTM(lstm_units)\n",
    "\n",
    "encoded1 = lstm_layer(embedding_layer(input1))\n",
    "encoded2 = lstm_layer(embedding_layer(input2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90210, 100)\n"
     ]
    }
   ],
   "source": [
    "embedding_weights = embedding_layer.get_weights()[0]\n",
    "print(embedding_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate \n",
    "merged = Concatenate()([encoded1, encoded2])\n",
    "\n",
    "# Add one or more Dense layers\n",
    "dense_units = 128  # Define the number of units in the dense layers\n",
    "\n",
    "dense1 = Dense(dense_units, activation='relu', kernel_initializer=HeNormal())(merged)  # Add a dense layer after the Concatenate layer\n",
    "dense2 = Dense(dense_units, activation='relu', kernel_initializer=HeNormal())(dense1)  # Optionally, you can add more dense layers\n",
    "\n",
    "# Add the final output layer\n",
    "output = Dense(1, activation='sigmoid')(dense2)\n",
    "\n",
    "model_lstm = Model(inputs=[input1, input2], outputs=output)\n",
    "\n",
    "model_lstm.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 40)]         0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 40)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 40, 100)      9021000     ['input_3[0][0]',                \n",
      "                                                                  'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 64)           42240       ['embedding_1[0][0]',            \n",
      "                                                                  'embedding_1[1][0]']            \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 128)          0           ['lstm_1[0][0]',                 \n",
      "                                                                  'lstm_1[1][0]']                 \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 128)          16512       ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 128)          16512       ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 1)            129         ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,096,393\n",
      "Trainable params: 9,096,393\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(model_lstm, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-06 17:27:39.847309: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-06 17:27:39.848665: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-06 17:27:39.849356: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-06 17:27:39.947987: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-06 17:27:39.948574: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-06 17:27:39.949152: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-06 17:27:40.464021: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-06 17:27:40.464886: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-06 17:27:40.465713: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-06 17:27:40.571428: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-06 17:27:40.572151: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-06 17:27:40.572677: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5054/5054 [==============================] - ETA: 0s - loss: 0.4657 - accuracy: 0.7755"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-06 17:31:31.139342: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-06 17:31:31.140102: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-06 17:31:31.140627: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-06 17:31:31.255816: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-06 17:31:31.256402: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-06 17:31:31.256880: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5054/5054 [==============================] - 239s 47ms/step - loss: 0.4657 - accuracy: 0.7755 - val_loss: 0.4103 - val_accuracy: 0.8103\n",
      "Epoch 2/5\n",
      "5054/5054 [==============================] - 551s 109ms/step - loss: 0.3403 - accuracy: 0.8484 - val_loss: 0.3897 - val_accuracy: 0.8245\n",
      "Epoch 3/5\n",
      "5054/5054 [==============================] - 234s 46ms/step - loss: 0.2631 - accuracy: 0.8874 - val_loss: 0.4116 - val_accuracy: 0.8307\n",
      "Epoch 4/5\n",
      "5054/5054 [==============================] - 236s 47ms/step - loss: 0.2047 - accuracy: 0.9145 - val_loss: 0.4219 - val_accuracy: 0.8315\n",
      "Epoch 5/5\n",
      "5054/5054 [==============================] - 240s 47ms/step - loss: 0.1605 - accuracy: 0.9344 - val_loss: 0.4768 - val_accuracy: 0.8281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x317633990>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "model_lstm.fit([X_train[:, :max_seq_length], X_train[:, max_seq_length:]], y_train, batch_size=64, epochs=5, validation_data=([X_test[:, :max_seq_length], X_test[:, max_seq_length:]], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-06 17:55:04.389475: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-06 17:55:04.390484: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-06 17:55:04.391065: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-10-06 17:55:04.481294: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-10-06 17:55:04.481822: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-10-06 17:55:04.482423: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2527/2527 [==============================] - 10s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.84      0.86     51026\n",
      "           1       0.74      0.81      0.78     29832\n",
      "\n",
      "    accuracy                           0.83     80858\n",
      "   macro avg       0.81      0.82      0.82     80858\n",
      "weighted avg       0.83      0.83      0.83     80858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming you have a trained model 'model'\n",
    "y_pred = model_lstm.predict([X_test[:, :max_seq_length], X_test[:, max_seq_length:]])\n",
    "\n",
    "# Convert the predictions to binary labels (0 or 1)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Transformer Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilbert-base-uncased\"  \n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indices = random.sample(range(len(df_train)), 30000)\n",
    "df_sampled = df_train.iloc[random_indices]\n",
    "\n",
    "#Sample 24,000 data points for training\n",
    "training_indices = random.sample(range(len(df_sampled)), 24000)\n",
    "df_train_v2 = df_sampled.iloc[training_indices]\n",
    "\n",
    "# Create an evaluation DataFrame with the remaining 6,000 data points\n",
    "evaluation_indices = [i for i in range(len(df_sampled)) if i not in training_indices]\n",
    "df_eval = df_sampled.iloc[evaluation_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sentence pairs and labels for training data\n",
    "sentence_pairs_train = [(row['question1'], row['question2']) for _, row in df_train_v2.iterrows()]\n",
    "labels_train = df_train_v2['is_duplicate'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare sentence pairs and labels for validation\n",
    "sentence_pairs_eval = [(row['question1'], row['question2']) for _, row in df_eval.iterrows()]\n",
    "labels_eval = df_eval['is_duplicate'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings_train = tokenizer(sentence_pairs_train, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "encodings_eval = tokenizer(sentence_pairs_eval, return_tensors=\"pt\", padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Dimension: torch.Size([24000, 136])\n"
     ]
    }
   ],
   "source": [
    "type(encodings_train)\n",
    "\n",
    "embedding_dim = encodings_train['input_ids'].shape\n",
    "print(\"Embedding Dimension:\", embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionPairClassificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "dataset_train = QuestionPairClassificationDataset(encodings_train, labels_train)\n",
    "dataloader = torch.utils.data.DataLoader(dataset_train, batch_size=8, shuffle=True)\n",
    "\n",
    "dataset_eval = QuestionPairClassificationDataset(encodings_eval, labels_eval)\n",
    "dataloader_eval = torch.utils.data.DataLoader(dataset_eval, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    report_to=\"tensorboard\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    save_steps=10_00,\n",
    "    save_total_limit=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=5_00,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    report_to=\"tensorboard\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    save_steps=10_00,\n",
    "    save_total_limit=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=5_00,\n",
    "    remove_unused_columns=False,\n",
    "    push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_eval,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d44a7a023a043639b400af043a15fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3525, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537e3641c38b4894abc144cd70d17ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8170190453529358, 'eval_runtime': 78.4087, 'eval_samples_per_second': 76.522, 'eval_steps_per_second': 9.565, 'epoch': 0.17}\n",
      "{'loss': 0.4959, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ca1d8670d94e96ad37bc3bb7120ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4624652862548828, 'eval_runtime': 105.2002, 'eval_samples_per_second': 57.034, 'eval_steps_per_second': 7.129, 'epoch': 0.33}\n",
      "{'loss': 0.4449, 'learning_rate': 2.5e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd29c423d3594e9db8e3d4e89ae0921e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4418240487575531, 'eval_runtime': 66.7798, 'eval_samples_per_second': 89.848, 'eval_steps_per_second': 11.231, 'epoch': 0.5}\n",
      "{'loss': 0.4366, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5cfd87c97394101bbc49d81137292c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.42845773696899414, 'eval_runtime': 74.9901, 'eval_samples_per_second': 80.011, 'eval_steps_per_second': 10.001, 'epoch': 0.67}\n",
      "{'loss': 0.4051, 'learning_rate': 8.333333333333334e-06, 'epoch': 0.83}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1c879706234766b152400cfbcba10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.41169074177742004, 'eval_runtime': 75.7228, 'eval_samples_per_second': 79.236, 'eval_steps_per_second': 9.905, 'epoch': 0.83}\n",
      "{'loss': 0.4112, 'learning_rate': 0.0, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d5e78222f2c4749b8f363d80c780c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4112699031829834, 'eval_runtime': 68.16, 'eval_samples_per_second': 88.028, 'eval_steps_per_second': 11.004, 'epoch': 1.0}\n",
      "{'train_runtime': 4154.4514, 'train_samples_per_second': 5.777, 'train_steps_per_second': 0.722, 'train_loss': 0.4243719482421875, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3000, training_loss=0.4243719482421875, metrics={'train_runtime': 4154.4514, 'train_samples_per_second': 5.777, 'train_steps_per_second': 0.722, 'train_loss': 0.4243719482421875, 'epoch': 1.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3471078d2e4b6ea353da5d382cde99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6814428567886353, 'eval_runtime': 178.6051, 'eval_samples_per_second': 33.594, 'eval_steps_per_second': 4.199}\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_dir = \"results/checkpoint-3000\" \n",
    "# tokenizer_bert = DistilBertTokenizer.from_pretrained(checkpoint_dir)\n",
    "# model_bert = DistilBertForSequenceClassification.from_pretrained(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Placeholder storage has not been allocated on MPS device!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/kianathakkar/Documents/NLPClassifier/quora_question_classifier.ipynb Cell 38\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kianathakkar/Documents/NLPClassifier/quora_question_classifier.ipynb#X51sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m labels \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kianathakkar/Documents/NLPClassifier/quora_question_classifier.ipynb#X51sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kianathakkar/Documents/NLPClassifier/quora_question_classifier.ipynb#X51sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(input_ids\u001b[39m=\u001b[39minput_ids, attention_mask\u001b[39m=\u001b[39mattention_mask)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kianathakkar/Documents/NLPClassifier/quora_question_classifier.ipynb#X51sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m logits \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mlogits\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kianathakkar/Documents/NLPClassifier/quora_question_classifier.ipynb#X51sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m batch_predictions \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(logits, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:789\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    782\u001b[0m \u001b[39mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    783\u001b[0m \u001b[39m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m \u001b[39m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m    785\u001b[0m \u001b[39m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    787\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m--> 789\u001b[0m distilbert_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistilbert(\n\u001b[1;32m    790\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m    791\u001b[0m     attention_mask\u001b[39m=\u001b[39mattention_mask,\n\u001b[1;32m    792\u001b[0m     head_mask\u001b[39m=\u001b[39mhead_mask,\n\u001b[1;32m    793\u001b[0m     inputs_embeds\u001b[39m=\u001b[39minputs_embeds,\n\u001b[1;32m    794\u001b[0m     output_attentions\u001b[39m=\u001b[39moutput_attentions,\n\u001b[1;32m    795\u001b[0m     output_hidden_states\u001b[39m=\u001b[39moutput_hidden_states,\n\u001b[1;32m    796\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[1;32m    797\u001b[0m )\n\u001b[1;32m    798\u001b[0m hidden_state \u001b[39m=\u001b[39m distilbert_output[\u001b[39m0\u001b[39m]  \u001b[39m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[1;32m    799\u001b[0m pooled_output \u001b[39m=\u001b[39m hidden_state[:, \u001b[39m0\u001b[39m]  \u001b[39m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:607\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[39m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    605\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 607\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(input_ids, inputs_embeds)  \u001b[39m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer(\n\u001b[1;32m    610\u001b[0m     x\u001b[39m=\u001b[39membeddings,\n\u001b[1;32m    611\u001b[0m     attn_mask\u001b[39m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    615\u001b[0m     return_dict\u001b[39m=\u001b[39mreturn_dict,\n\u001b[1;32m    616\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/distilbert/modeling_distilbert.py:120\u001b[0m, in \u001b[0;36mEmbeddings.forward\u001b[0;34m(self, input_ids, input_embeds)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39mParameters:\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[39m    input_ids (torch.Tensor):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39membeddings)\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39mif\u001b[39;00m input_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m     input_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword_embeddings(input_ids)  \u001b[39m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[1;32m    122\u001b[0m seq_length \u001b[39m=\u001b[39m input_embeds\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m)\n\u001b[1;32m    124\u001b[0m \u001b[39m# Setting the position-ids to the registered buffer in constructor, it helps\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39m# when tracing the model without passing position-ids, solves\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39m# isues similar to issue #5664\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39membedding(\n\u001b[1;32m    163\u001b[0m         \u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_idx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_norm,\n\u001b[1;32m    164\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm_type, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale_grad_by_freq, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparse)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39membedding(weight, \u001b[39minput\u001b[39m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Placeholder storage has not been allocated on MPS device!"
     ]
    }
   ],
   "source": [
    "# predictions = []\n",
    "# true_labels = []\n",
    "\n",
    "# # Set the model to evaluation mode\n",
    "# model.eval()\n",
    "\n",
    "# for batch in dataloader_eval:\n",
    "#     input_ids = batch['input_ids']\n",
    "#     attention_mask = batch['attention_mask']\n",
    "#     labels = batch['labels']\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "#     logits = outputs.logits\n",
    "#     batch_predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "#     predictions.extend(batch_predictions.tolist())\n",
    "#     true_labels.extend(labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# accuracy = accuracy_score(true_labels, predictions)\n",
    "# precision = precision_score(true_labels, predictions)\n",
    "# recall = recall_score(true_labels, predictions)\n",
    "# f1 = f1_score(true_labels, predictions)\n",
    "\n",
    "# print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "# print(f\"Precision: {precision:.2f}\")\n",
    "# print(f\"Recall: {recall:.2f}\")\n",
    "# print(f\"F1 Score: {f1:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
